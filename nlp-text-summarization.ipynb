{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc087810",
      "metadata": {
        "id": "cc087810"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"In a world often dominated by negativity, it's important to remember the power of kindness and compassion. Small acts of kindness have the ability to brighten someone's day, uplift spirits, and create a ripple effect of positivity that can spread far and wide. Whether it's a smile to a stranger, a helping hand to a friend in need, or a thoughtful gesture to a colleague, every act of kindness has the potential to make a difference in someone's life.Beyond individual actions, there is also immense power in collective efforts to create positive change. When communities come together to support one another, incredible things can happen. From grassroots initiatives to global movements, people are uniting to tackle pressing social and environmental issues, driving meaningful progress and inspiring hope for a better future.It's also important to recognize the strength that lies within each and every one of us. We all have the ability to make a positive impact, no matter how small our actions may seem. By tapping into our innate compassion and empathy, we can cultivate a culture of kindness and empathy that enriches our lives and those around us.So let's embrace the power of kindness, and strive to make the world a better place one small act at a time. Together, we can create a brighter, more compassionate future for all.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294bd1c0",
      "metadata": {
        "id": "294bd1c0",
        "outputId": "b00195b9-f932-4c4f-9332-59c0b2485bf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1335"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22d7351",
      "metadata": {
        "id": "c22d7351"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ccd6d2",
      "metadata": {
        "id": "76ccd6d2",
        "outputId": "919dbd3d-3c4b-42af-c67e-de10c3b3fdcc"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
            "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c61dea4",
      "metadata": {
        "id": "6c61dea4"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "043b45c1",
      "metadata": {
        "id": "043b45c1"
      },
      "outputs": [],
      "source": [
        "#tokenization of text\n",
        "tokens = [token.text.lower() for token in doc\n",
        "          if not token.is_stop and\n",
        "          not token.is_punct and\n",
        "          token.text !='\\n']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4a914f",
      "metadata": {
        "id": "6a4a914f"
      },
      "outputs": [],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51e27091",
      "metadata": {
        "id": "51e27091"
      },
      "outputs": [],
      "source": [
        "tokens1=[]\n",
        "stopwords = list(STOP_WORDS)\n",
        "allowed_pos = ['ADJ','PROPN','VERB','NOUN']\n",
        "for token in doc:\n",
        "    if token.text in stopwords or token.text in punctuation:\n",
        "        continue\n",
        "    if token.pos_ in allowed_pos:\n",
        "        tokens1.append(token.text)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6505766f",
      "metadata": {
        "id": "6505766f"
      },
      "outputs": [],
      "source": [
        "tokens1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5507a3",
      "metadata": {
        "id": "ea5507a3"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ea3d1d",
      "metadata": {
        "id": "48ea3d1d"
      },
      "outputs": [],
      "source": [
        "word_freq = Counter(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5bdce2",
      "metadata": {
        "id": "3e5bdce2"
      },
      "outputs": [],
      "source": [
        "word_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc3b699",
      "metadata": {
        "id": "1bc3b699"
      },
      "outputs": [],
      "source": [
        "max_freq = max(word_freq.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "666931b9",
      "metadata": {
        "id": "666931b9"
      },
      "outputs": [],
      "source": [
        "max_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da198abe",
      "metadata": {
        "id": "da198abe"
      },
      "outputs": [],
      "source": [
        "for word in word_freq.keys():\n",
        "    word_freq[word] = word_freq[word]/max_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9984b3a",
      "metadata": {
        "id": "b9984b3a"
      },
      "outputs": [],
      "source": [
        "word_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01a6104",
      "metadata": {
        "id": "f01a6104"
      },
      "outputs": [],
      "source": [
        "sent_token = [sent.text for sent in doc.sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb7b1fe7",
      "metadata": {
        "id": "fb7b1fe7"
      },
      "outputs": [],
      "source": [
        "sent_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c0ef0a",
      "metadata": {
        "id": "96c0ef0a"
      },
      "outputs": [],
      "source": [
        "sent_score = {}\n",
        "for sent in sent_token:\n",
        "    for word in sent.split():\n",
        "        if word.lower() in word_freq.keys():\n",
        "            if sent not in sent_score.keys():\n",
        "                sent_score[sent] = word_freq[word]\n",
        "            else:\n",
        "                sent_score[sent] +=word_freq[word]\n",
        "        print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d81aaad",
      "metadata": {
        "id": "7d81aaad"
      },
      "outputs": [],
      "source": [
        "sent_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c87806",
      "metadata": {
        "id": "25c87806"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9be5c6",
      "metadata": {
        "id": "cd9be5c6"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(list(sent_score.items()),columns=['Sentence','Score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a6b3c7d",
      "metadata": {
        "id": "6a6b3c7d"
      },
      "outputs": [],
      "source": [
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab13760d",
      "metadata": {
        "id": "ab13760d"
      },
      "outputs": [],
      "source": [
        "num_sentences =3\n",
        "n = nlargest(num_sentences,sent_score,key=sent_score.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b612b5ca",
      "metadata": {
        "id": "b612b5ca"
      },
      "outputs": [],
      "source": [
        "\" \".join(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d588264",
      "metadata": {
        "id": "2d588264"
      },
      "outputs": [],
      "source": [
        "# Importing the summarization code\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from heapq import nlargest\n",
        "\n",
        "def summarize_text(text):\n",
        "\n",
        "    # Loading spaCy model\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "    # Tokenization and removing stopwords\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text.lower() for token in doc\n",
        "              if not token.is_stop and not token.is_punct and token.text != '\\n']\n",
        "\n",
        "    # Calculating word frequency\n",
        "    word_freq = Counter(tokens)\n",
        "    if not word_freq:\n",
        "\n",
        "        return \"Error: No words found in the text.\"\n",
        "\n",
        "    max_freq = max(word_freq.values())\n",
        "    for word in word_freq.keys():\n",
        "        word_freq[word] = word_freq[word]/max_freq\n",
        "\n",
        "    # Sentence tokenization\n",
        "    sent_token = [sent.text for sent in doc.sents]\n",
        "\n",
        "    sent_score = {}\n",
        "    for sent in sent_token:\n",
        "        for word in sent.split():\n",
        "            if word.lower() in word_freq.keys():\n",
        "                if sent not in sent_score.keys():\n",
        "                    sent_score[sent] = word_freq[word]\n",
        "                else:\n",
        "                    sent_score[sent] += word_freq[word]\n",
        "\n",
        "    # Select top-scoring sentences based on user input\n",
        "    num_sentences = int(num_sentences_entry.get())\n",
        "    summarized_sentences = nlargest(num_sentences, sent_score, key=sent_score.get)\n",
        "\n",
        "    return summarized_sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd184e1e",
      "metadata": {
        "id": "fd184e1e"
      },
      "outputs": [],
      "source": [
        "#using transformer to summarize the text.\n",
        "\n",
        "from transformers import pipeline\n",
        "summarizer=pipeline(\"summarization\",model='t5-base',tokenizer='t5-base',framework='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb35c13",
      "metadata": {
        "id": "0cb35c13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28a7c9b",
      "metadata": {
        "id": "a28a7c9b"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"In a world often dominated by negativity, it's important to remember the power of kindness and compassion. Small acts of kindness have the ability to brighten someone's day, uplift spirits, and create a ripple effect of positivity that can spread far and wide. Whether it's a smile to a stranger, a helping hand to a friend in need, or a thoughtful gesture to a colleague, every act of kindness has the potential to make a difference in someone's life.Beyond individual actions, there is also immense power in collective efforts to create positive change. When communities come together to support one another, incredible things can happen. From grassroots initiatives to global movements, people are uniting to tackle pressing social and environmental issues, driving meaningful progress and inspiring hope for a better future.It's also important to recognize the strength that lies within each and every one of us. We all have the ability to make a positive impact, no matter how small our actions may seem. By tapping into our innate compassion and empathy, we can cultivate a culture of kindness and empathy that enriches our lives and those around us.So let's embrace the power of kindness, and strive to make the world a better place one small act at a time. Together, we can create a brighter, more compassionate future for all.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cbb410",
      "metadata": {
        "id": "d9cbb410"
      },
      "outputs": [],
      "source": [
        "summary = summarizer(text,max_length=100,min_length=10,do_sample=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "121e7e26",
      "metadata": {
        "id": "121e7e26"
      },
      "outputs": [],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0266e51f",
      "metadata": {
        "id": "0266e51f"
      },
      "outputs": [],
      "source": [
        "print(summary[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c09ccdc",
      "metadata": {
        "id": "4c09ccdc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06acf375",
      "metadata": {
        "id": "06acf375"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}